{
 "cells": {
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from urllib.parse import quote, unquote\n",
    "from html import unescape\n",
    "import json\n",
    "\n",
    "# Endpoint and headers\n",
    "url = \"https://redsky.target.com/redsky_aggregations/v1/web/plp_search_v2?\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36'}\n",
    "\n",
    "# List of ingredients to be able to loop\n",
    "ingredients = [\"unsalted butter\", \"granulated sugar\", \"brown sugar\", \"eggs\", \"vanilla extract\", \"baking soda\", \"all purpose flour\", \"semi-sweet chocolate chip\", \"chopped walnuts\"]\n",
    "\n",
    "# Parameters for the API\n",
    "parameters = {\n",
    "    \"key\": \"9f36aeafbe60771e321a7cc95a78140772ab3e96\",\n",
    "    \"channel\": \"WEB\",\n",
    "    \"count\": 24,\n",
    "    \"default_purchasability_filter\": \"true\",\n",
    "    \"include_dmc_dmr\": \"true\",\n",
    "    \"include_sponsored\": \"true\",\n",
    "    \"new_search\": \"true\",\n",
    "    \"platform\": \"desktop\",\n",
    "    \"pricing_store_id\": 2455,\n",
    "    \"spellcheck\": \"true\",\n",
    "    \"store_ids\": [2455, 2268, 2408, 310, 3384],\n",
    "    \"visitor_id\": \"01939852639E02019551A1FC131A3326\",\n",
    "    \"zip\": 95616\n",
    "}\n",
    "\n",
    "def target_scraper(ingredient, regex_pattern):\n",
    "    all_results = []\n",
    "    offset = 0\n",
    "\n",
    "    while True:\n",
    "        # Update parameters dynamically for each request\n",
    "        encoded_ingredient = quote(ingredient)\n",
    "        parameters[\"keyword\"] = ingredient\n",
    "        parameters[\"page\"] = f\"/s/{encoded_ingredient}\"\n",
    "        parameters[\"offset\"] = offset\n",
    "\n",
    "        response = requests.get(url, params=parameters, headers=headers)\n",
    "        \n",
    "        # Check if response is successful\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error fetching data for {ingredient}: {response.status_code}\")\n",
    "            break\n",
    "\n",
    "        # Load response data\n",
    "        try:\n",
    "            data = response.json()\n",
    "            products = data[\"data\"][\"search\"][\"products\"]\n",
    "        except (KeyError, json.JSONDecodeError):\n",
    "            print(f\"Error parsing data for {ingredient}\")\n",
    "            break\n",
    "        \n",
    "        # If no more products, exit loop\n",
    "        if not products:\n",
    "            break\n",
    "\n",
    "        # Extract product name and price\n",
    "        for product in products:\n",
    "            title = product['item']['product_description']['title']\n",
    "            price = product['price']['current_retail']\n",
    "            decoded_title = unescape(unquote(title))\n",
    "\n",
    "            # Filter products based on the regex pattern\n",
    "            if re.search(regex_pattern, decoded_title, flags=re.IGNORECASE):\n",
    "                all_results.append({'ingredient': ingredient, 'product_name': decoded_title, 'price': price})\n",
    "\n",
    "        # Increment offset for next page\n",
    "        offset += 24\n",
    "\n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "# Define ingredient list and their filtering terms\n",
    "filter_terms = {\n",
    "    \"unsalted butter\": r\"unsalted butter\",\n",
    "    \"granulated sugar\": r\"granulated sugar\",\n",
    "    \"brown sugar\": r\" dark brown sugar\",\n",
    "    \"eggs\": r\"eggs\",\n",
    "    \"vanilla extract\": r\"vanilla extract\",\n",
    "    \"baking soda\": r\"baking soda\",\n",
    "    \"all purpose flour\": r\"all purpose flour|all\\-purpose flour\",\n",
    "    \"semi-sweet chocolate chip\": r\"semi sweet chocolate|semi\\-sweet chocolate\",\n",
    "    \"chopped walnuts\": r\"chopped walnuts\"\n",
    "}\n",
    "\n",
    "# Loop through each ingredient and collect data\n",
    "main_df = pd.DataFrame()\n",
    "for ingredient, regex_pattern in filter_terms.items():\n",
    "    print(f\"Scraping for: {ingredient}\")\n",
    "    ingredient_df = target_scraper(ingredient, regex_pattern)\n",
    "    main_df = pd.concat([main_df, ingredient_df], ignore_index=True)\n",
    "\n",
    "main_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "def extract_amount(product_name):\n",
    "    # Extracing the amount by using common units\n",
    "    matches = re.findall(r\"(\\d+\\.?\\d*)\\s?(fl\\.?\\s?oz|oz|lb|lbs|g|kg|ml|l|ct|pcs|pack|case|floz)\", product_name, re.IGNORECASE)\n",
    "    if matches:\n",
    "        return f\"{matches[-1][0]} {matches[-1][1].replace('.', '').lower()}\"\n",
    "    return None\n",
    "\n",
    "# Creates an amount value for each of the products\n",
    "main_df[\"amount\"] = main_df[\"product_name\"].apply(extract_amount)\n",
    "\n",
    "# Remove rows with None in the \"amount\" column\n",
    "main_df = main_df[main_df[\"amount\"].notna()]\n",
    "\n",
    "def filter_eggs(df):\n",
    "    # Filtering out egg products that contain the word large, candy, or hard since they are not the type of eggs we are looking for\n",
    "    return df[~((df[\"ingredient\"] == \"eggs\") & \n",
    "                ((df[\"product_name\"].str.contains(\"hard\", case=False)) | \n",
    "                 (~df[\"product_name\"].str.contains(\"large\", case=False)) |\n",
    "                 (df[\"product_name\"].str.contains(\"candy\", case=False))))]\n",
    "\n",
    "filtered_df = filter_eggs(main_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for filtering out products that don't meet our minimum required amount per ingredient\n",
    "FILTER_CRITERIA = {\n",
    "    \"unsalted butter\": {\"lb\": 0.5, \"ct\": 2},\n",
    "    \"granulated sugar\": {\"lb\": 0.5},\n",
    "    \"brown sugar\": {\"lb\": 0.5, \"oz\": 7},\n",
    "    \"eggs\": {\"ct\": 2},\n",
    "    \"all purpose flour\": {\"lb\": 1, \"g\": 120, \"oz\": 4},\n",
    "    \"semi-sweet chocolate chip\": {\"oz\": 12},\n",
    "    \"chopped walnuts\": {\"oz\": 6},\n",
    "    # Baking soda and vanilla extract will not need filtering as all products have enough (1-2 tablespoons)\n",
    "}\n",
    "\n",
    "def meets_criteria(row):\n",
    "    # Filtering out products that dont meet the filtering criteria\n",
    "    ingredient = row[\"ingredient\"]\n",
    "    \n",
    "    # If the ingredient is baking soda or vanilla extract, keep it as is as these products have enough\n",
    "    if ingredient in [\"baking soda\", \"vanilla extract\"]:\n",
    "        return True\n",
    "\n",
    "    amount_unit = row[\"amount\"].split()\n",
    "    \n",
    "    if len(amount_unit) != 2:\n",
    "        return False\n",
    "    \n",
    "    amount, unit = amount_unit\n",
    "    amount = float(amount)\n",
    "    \n",
    "    # Check if the unit and amount match the criteria for this ingredient\n",
    "    if ingredient in FILTER_CRITERIA and unit in FILTER_CRITERIA[ingredient]:\n",
    "        return amount >= FILTER_CRITERIA[ingredient][unit]\n",
    "    \n",
    "    return False\n",
    "\n",
    "filtered_df = filtered_df[filtered_df.apply(meets_criteria, axis=1)]\n",
    "\n",
    "filtered_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.copy()\n",
    "\n",
    "# Sort the DataFrame to prioritize dark brown sugar and lowest price for each ingredient\n",
    "filtered_df.sort_values(by=['ingredient', 'price'], ascending=[True, True], inplace=True)\n",
    "\n",
    "# Drop duplicates to keep only the cheapest product per unique ingredient\n",
    "cheapest_ingredients = filtered_df.drop_duplicates(subset='ingredient', keep='first')\n",
    "\n",
    "cheapest_ingredients.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(cheapest_ingredients[[\"ingredient\",\"product_name\",\"price\",\"amount\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Davis Co-op Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endpoint URL and header\n",
    "url = \"https://daviscoop.storebyweb.com/s/1000-1/api/b/\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.3\"}\n",
    "\n",
    "ingredients = [\"unsalted butter\", \"granulated sugar\", \"dark brown sugar\", \"eggs\", \"vanilla extract\", \"baking soda\", \"all purpose flour\", \"semi-sweet chocolate chip\", \"walnuts\"]\n",
    "\n",
    "parameters = {\"facets\": {}, \"ps\": 32, \"s\": \"\", \"g\": []}\n",
    "\n",
    "def coop_scraper(ingredient, regex_pattern):\n",
    "    all_results = []\n",
    "    pn = 1\n",
    "\n",
    "    while True:\n",
    "        parameters[\"pn\"] = pn\n",
    "        parameters[\"q\"] = ingredient\n",
    "\n",
    "        response = requests.post(url, json=parameters, headers=headers)\n",
    "        \n",
    "        # Check if response is successful\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error fetching data for {ingredient}: {response.status_code}\")\n",
    "            break\n",
    "\n",
    "        # Load response data\n",
    "        try:\n",
    "            data = response.json()\n",
    "            products = data.get(\"items\",[])\n",
    "        except (KeyError, json.JSONDecodeError):\n",
    "            print(f\"Error parsing data for {ingredient}\")\n",
    "            break\n",
    "        \n",
    "        # If no more products, exit loop\n",
    "        if not products:\n",
    "            break\n",
    "\n",
    "        # Extract product name and price\n",
    "        for product in products:\n",
    "            title = product['name']\n",
    "            price = product['actualPrice']\n",
    "            amount = product['size']\n",
    "            brand = product['brand']\n",
    "            decoded_title = unescape(unquote(title))\n",
    "\n",
    "            # Filter products based on the regex pattern\n",
    "            if re.search(regex_pattern, decoded_title, flags=re.IGNORECASE):\n",
    "                all_results.append({'ingredient': ingredient, 'product_name': decoded_title, 'price': price, 'amount': amount, \"brand\": brand})\n",
    "\n",
    "        if len(products) < parameters[\"ps\"]:\n",
    "            break\n",
    "\n",
    "        # Increment offset for next page\n",
    "        pn += 1\n",
    "    \n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "# Define ingredient list and their filtering terms\n",
    "filter_terms = {\n",
    "    \"unsalted butter\": r\"unsalted butter\",\n",
    "    \"granulated sugar\": r\"granulated sugar\",\n",
    "    \"brown sugar\": r\"dark brown sugar\",\n",
    "    \"eggs\": r\"eggs\",\n",
    "    \"vanilla extract\": r\"vanilla extract\",\n",
    "    \"baking soda\": r\"baking soda\",\n",
    "    \"all purpose flour\": r\"all purpose flour|all\\-purpose flour\",\n",
    "    \"semi-sweet chocolate chip\": r\"semi sweet chocolate|semi\\-sweet chocolate\",\n",
    "    \"walnuts\": r\"walnuts\"\n",
    "}\n",
    "\n",
    "main2_df = pd.DataFrame()\n",
    "for ingredient, regex_pattern in filter_terms.items():\n",
    "    print(f\"Scraping for: {ingredient}\")\n",
    "    ingredient_df = coop_scraper(ingredient, regex_pattern)\n",
    "    main2_df = pd.concat([main2_df, ingredient_df], ignore_index=True)\n",
    "\n",
    "main2_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "def filter_eggs(df):\n",
    "    # Exclude products that contain words that signal on egg products we are not looking for\n",
    "    return df[~((df[\"ingredient\"] == \"eggs\") & \n",
    "                ((df[\"product_name\"].str.contains(\"hard\", case=False)) | \n",
    "                 (~df[\"product_name\"].str.contains(\"large\", case=False)) |\n",
    "                 (df[\"product_name\"].str.contains(\"candy\", case=False))))]\n",
    "\n",
    "def filter_brown_sugar(df):\n",
    "    # Exclude products that contain keywords like wafels that we are not looking for\n",
    "    return df[~((df[\"ingredient\"] == \"brown sugar\") & \n",
    "                ((df[\"product_name\"].str.contains(\"creamer\", case=False)) | \n",
    "                 (df[\"product_name\"].str.contains(\"maple\", case=False)) |\n",
    "                 (df[\"product_name\"].str.contains(\"replacement\", case=False)) |\n",
    "                 (df[\"product_name\"].str.contains(\"wafels\", case=False)) |\n",
    "                 (df[\"product_name\"].str.contains(\"ice\", case=False)) |\n",
    "                 (df[\"product_name\"].str.contains(\"milk\", case=False)) |\n",
    "                 (df[\"product_name\"].str.contains(\"latte\", case=False))))]\n",
    "\n",
    "def filter_walnuts(df):\n",
    "    # Excluding walnut products from sprouted as they are not the type of walnuts we are looking for\n",
    "    return df[~((df[\"ingredient\"] == \"walnuts\") & \n",
    "                ((df[\"product_name\"].str.contains(\"sprouted\", case=False))))]\n",
    "\n",
    "filtered_df2 = filter_eggs(main2_df)\n",
    "filtered_df2 = filter_brown_sugar(filtered_df2)\n",
    "filtered_df2 = filter_walnuts(filtered_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for filtering out products that don't meet our minimum required amount per ingredient\n",
    "FILTER_CRITERIA = {\n",
    "    \"unsalted butter\": {\"oz.\": 8},\n",
    "    \"granulated sugar\": {\"oz.\": 8},\n",
    "    \"brown sugar\": {\"lb.\": 0.5, \"oz.\": 7},\n",
    "    \"eggs\": {\"ct.\": 2},\n",
    "    \"all purpose flour\": {\"lb.\": 1, \"g.\": 120, \"oz.\": 4},\n",
    "    \"semi-sweet chocolate chip\": {\"oz.\": 12},\n",
    "    \"walnuts\": {\"oz.\": 6},\n",
    "    # Baking soda and vanilla extract will not need filtering as all products have enough (1-2 tablespoons)\n",
    "}\n",
    "\n",
    "def meets_criteria(row):\n",
    "    # Filtering out products that dont meet the filtering criteria\n",
    "    ingredient = row[\"ingredient\"]\n",
    "    \n",
    "    # If the ingredient is baking soda or vanilla extract, keep it as is as these products have enough\n",
    "    if ingredient in [\"baking soda\", \"vanilla extract\"]:\n",
    "        return True\n",
    "\n",
    "    amount_unit = row[\"amount\"].split()\n",
    "    \n",
    "    if len(amount_unit) != 2:\n",
    "        return False\n",
    "    \n",
    "    amount, unit = amount_unit\n",
    "    amount = float(amount)\n",
    "    \n",
    "    # Check if the unit and amount match the criteria for this ingredient\n",
    "    if ingredient in FILTER_CRITERIA and unit in FILTER_CRITERIA[ingredient]:\n",
    "        return amount >= FILTER_CRITERIA[ingredient][unit]\n",
    "    \n",
    "    return False\n",
    "\n",
    "def preprocess_amount_column(df):\n",
    "    # Some rows have invalid format so clean out the data frame to be able to run the filtering code by making sure every value in \"amount\" is a valid format\n",
    "    cleaned_rows = []\n",
    "    for index, row in df.iterrows():\n",
    "        amount_unit = row[\"amount\"].split()\n",
    "        if len(amount_unit) == 2:  # Only keep rows with exactly two parts: number and unit\n",
    "            try:\n",
    "                float(amount_unit[0])\n",
    "                cleaned_rows.append(row)\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return pd.DataFrame(cleaned_rows)\n",
    "\n",
    "# Clean the 'amount' column\n",
    "filtered_df2 = preprocess_amount_column(filtered_df2)\n",
    "\n",
    "filtered_df2 = filtered_df2[filtered_df2.apply(meets_criteria, axis=1)]\n",
    "\n",
    "filtered_df2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "filtered_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure a clean DataFrame\n",
    "filtered_df2 = filtered_df2.copy()\n",
    "\n",
    "# Sort the DataFrame to prioritize dark brown sugar and lowest price for each ingredient\n",
    "filtered_df2.sort_values(by=['ingredient', 'price'], ascending=[True, True], inplace=True)\n",
    "\n",
    "# Drop duplicates to keep only the cheapest product per unique ingredient\n",
    "cheapest_ingredients = filtered_df2.drop_duplicates(subset='ingredient', keep='first')\n",
    "\n",
    "cheapest_ingredients.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(cheapest_ingredients)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
