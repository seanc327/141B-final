{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "1. Getting the best recipe from AllRecipes\n",
    "2. Getting products from Trader Joe's\n",
    "3. Getting products from SaveMart\n",
    "4. Getting products from Safeway\n",
    "5. Getting products from Target\n",
    "6. Getting products from Davis Food Co-op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the best recipe code\n",
    "\n",
    "note: user has to input desired search url\n",
    "\n",
    "code function:\n",
    "1. extracts all recipe links from the search page\n",
    "2. scrapes title, stars, and number of ratings from each of the links extracted\n",
    "3. sorts each recipe according to the descending number of ratings, then descending stars\n",
    "4. converts dictionary into data frame for organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import parse_qs, urlparse\n",
    "\n",
    "# function that extracts each recipe link from search page (url)\n",
    "def extractlinks(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    #extract anchor tags w/ links\n",
    "    cards = soup.find_all('a', href = True)\n",
    "    links = [link['href'] for link in cards if '/recipe/' in link['href']]\n",
    "    \n",
    "    return list(set(links))\n",
    "\n",
    "# function that scrapes title, stars, number of ratings    \n",
    "def scrapedetails(rurl, searchq):\n",
    "    response = requests.get(rurl)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    #scrape title\n",
    "    telement = soup.select_one(\"h1.article-heading\")\n",
    "    title = telement.get_text(strip = True) if telement else \"n/a\"\n",
    "    \n",
    "    #scrape stars (0 - 5)\n",
    "    selement = soup.select_one(\"div.mm-recipes-review-bar__rating.mntl-text-block.text-label-300\")\n",
    "    stars = float(selement.get_text(strip = True)) if selement else 0.0\n",
    "    \n",
    "    #scrape number of ratings\n",
    "    relement = soup.select_one(\"div.mm-recipes-review-bar__rating-count.mntl-text-block.text-label-300\")\n",
    "    \n",
    "    #if/else to determine if rating number exists. \n",
    "    if relement:\n",
    "        #note: if exists, it strips html of text (such as </div>) and ()\n",
    "        ratingtext = relement.get_text(strip = True)\n",
    "        ratingnum = int(ratingtext.strip(\"()\").replace(\",\", \"\"))\n",
    "    else:\n",
    "        ratingnum = 0\n",
    "    \n",
    "    #matching search keywords with title\n",
    "    if searchq.lower() not in title.lower():\n",
    "        return None\n",
    "    \n",
    "    #dictionary for details scraped\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"stars\": stars,\n",
    "        \"ratings\": ratingnum\n",
    "    }\n",
    "    \n",
    "# function that fetches recipe from search page, then uses scrapedetails() to scrape specifics\n",
    "def scrapeall(url, searchq):\n",
    "    links = extractlinks(url)\n",
    "    \n",
    "    #list to store recipe links\n",
    "    allrecipes = []\n",
    "    \n",
    "    #loops through each link and calls previous function to scrape details\n",
    "    for link in links:\n",
    "        rdetails = scrapedetails(link, searchq)\n",
    "        if rdetails:\n",
    "            #update list to store dictionary\n",
    "            allrecipes.append(rdetails)\n",
    "    \n",
    "    return allrecipes\n",
    "\n",
    "# sort function that sorts by descending number of ratings first, then descending number of stars\n",
    "def sort(recipes): \n",
    "    rsorted = sorted(recipes, key = lambda x: (-x['ratings'], -x['stars']))\n",
    "    return rsorted\n",
    "\n",
    "# extract serach query from url\n",
    "def extractsearchq(url):\n",
    "    query = parse_qs(urlparse(url).query)\n",
    "    search = query.get(\"q\", [\"\"])[0]\n",
    "    searchq = search.replace(\"+\", \" \")\n",
    "    return searchq\n",
    "\n",
    "# main function\n",
    "def main():\n",
    "    url = input(\"paste search url here:\")\n",
    "    # specifically https://www.allrecipes.com/search?q=chocolate+chip+cookies for our project\n",
    "    searchq = extractsearchq(url)\n",
    "    recipes = scrapeall(url, searchq)\n",
    "    rsorted = sort(recipes)\n",
    "    \n",
    "    #convert to data frame for organization purposes\n",
    "    df = pd.DataFrame(rsorted)\n",
    "    df.insert(0, \"rank\", range(1, 1 + len(df)))\n",
    "    print(df.to_string(index = False))\n",
    "    return df.head(1)[\"url\"][0] # return url of the top recipe\n",
    "\n",
    "# call main function\n",
    "if __name__ == '__main__':\n",
    "    top_recipe = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts the ingredients given an allrecipe recipe link\n",
    "def get_ingredients(url:str):\n",
    "    # Send a GET request to fetch the page content\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # Find the <div> with the specific id\n",
    "    div = soup.find('div', id='mm-recipes-structured-ingredients_1-0')\n",
    "\n",
    "    # Find all <ul> elements within the <div>\n",
    "    ul_elements = div.find_all('ul')\n",
    "\n",
    "    # Initialize empty lists to store the ingredient data\n",
    "    quantities = []\n",
    "    units = []\n",
    "    ingredient_names = []\n",
    "\n",
    "    # Loop through all <ul> elements\n",
    "    for ul in ul_elements:\n",
    "        # Find all <li> elements within the <ul>\n",
    "        li_elements = ul.find_all('li')\n",
    "\n",
    "        # Loop through each <li> to extract the ingredients\n",
    "        for li in li_elements:\n",
    "            # Find the <p> elements within each <li>\n",
    "            p_elements = li.find_all('p')\n",
    "             \n",
    "            # Assuming the <p> elements have <span> elements for quantity, unit, and ingredient\n",
    "            for p in p_elements:\n",
    "                spans = p.find_all('span')  # Find all <span> elements within each <p>\n",
    "                \n",
    "                if len(spans) == 3:  # We expect 3 spans: quantity, unit, and ingredient name\n",
    "                    quantity = spans[0].get_text(strip=True)\n",
    "                    unit = spans[1].get_text(strip=True)\n",
    "                    ingredient_name = spans[2].get_text(strip=True)\n",
    "                    \n",
    "                    # Append the data to the lists\n",
    "                    quantities.append(quantity)\n",
    "                    units.append(unit)\n",
    "                    ingredient_names.append(ingredient_name)\n",
    "\n",
    "    # Create a pandas DataFrame from the extracted data\n",
    "    df = pd.DataFrame({\n",
    "        'quantity': quantities,\n",
    "        'unit': units,\n",
    "        'ingredient name': ingredient_names\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_df = get_ingredients(top_recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.html as lx\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize list of ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_list = [\"unsalted butter\",\"all-purpose flour\",\"white sugar\",\n",
    "                    \"vanilla extract\",\"brown sugar\",\n",
    "                    \"large eggs\",\"baking soda\",\"semisweet chocolate chips\",\n",
    "                    \"chopped walnuts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize dictionary to store results of each search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dictionaries for dataframe results for each store\n",
    "def initialize_ingredients_dict():\n",
    "    global ingredients_list\n",
    "    # Initialize dictionary with ingredients as keys and None as values\n",
    "    ingredients_dict = {ingredient: None for ingredient in ingredients_list}\n",
    "    return ingredients_dict\n",
    "\n",
    "# initialize dictionary for each store\n",
    "tjs = initialize_ingredients_dict()\n",
    "svmrt = initialize_ingredients_dict()\n",
    "sfwy = initialize_ingredients_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to filter for sufficient quantity and right product and sort by price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the text by removing spaces and punctuation and converting to lowercase\n",
    "def preprocess(text:str):\n",
    "    if not isinstance(text,str):\n",
    "        return None\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to filter rows based on keywords\n",
    "def filter_rows_by_keywords(df:pd.DataFrame,keywords:list,exclude_keywords:list,must_have:list,min_matches=2):\n",
    "    # Function to count how many keywords are found in a row\n",
    "    def count_keywords(row, keywords:list):\n",
    "        return sum(keyword.lower() in row for keyword in keywords)\n",
    "    \n",
    "    # Function to check if any must exclude keywords are in a row\n",
    "    def contains_exclude_keywords(row, exclude_keywords:list):\n",
    "        return any(exclude_keyword.lower() in row for exclude_keyword in exclude_keywords)\n",
    "    \n",
    "    # Function to check if all must-have keywords are found in a row\n",
    "    def contains_must_have_keywords(row, must_have_keywords:list):\n",
    "        return all(keyword.lower() in row for keyword in must_have_keywords)\n",
    "\n",
    "    df['Name'] = df[\"Name\"].str.lower() # case insensitive matching\n",
    "    \n",
    "    # filter based on must-have, nice-to-have, and must exclude keywords\n",
    "    # product must have at least 2 nice-to-have keywords to be considered\n",
    "    return df[\n",
    "        df[\"Name\"].apply(lambda row: count_keywords(row, keywords) >= min_matches) &\n",
    "        ~df[\"Name\"].apply(lambda row: contains_exclude_keywords(row, exclude_keywords) if exclude_keywords else False) &\n",
    "        df[\"Name\"].apply(lambda row: contains_must_have_keywords(row, must_have))\n",
    "        ]\n",
    "\n",
    "# Function to check if a product has enough quantity\n",
    "def check_sufficient_quantity(ingredient:str,row):\n",
    "    # define acceptable quantities for each ingredient\n",
    "    qties = {\n",
    "        \"unsalted butter\":{\"ea\":2,\"sticks\":2,\"lb\":.5,\"oz\":8},\n",
    "        \"white sugar\":{\"oz\":7,\"lb\":.44},\n",
    "        \"all-purpose flour\":{\"lb\":3*0.275578,\"oz\":3*4.40925},\n",
    "        \"vanilla extract\":{\"fl oz\":.2,'oz':.2},\n",
    "        \"dark brown sugar\":{\"oz\":7,\"lb\":.44},\n",
    "        \"large eggs\":{\"doz\":2/12,\"ct\":2,\"count\":2,\"ea\":2},\n",
    "        \"baking soda\":{\"lb\":.0125,\"oz\":.2},\n",
    "        \"semisweet chocolate chips\":{\"oz\":12},\n",
    "        \"chopped walnuts\":{\"oz\":4.4,\"lb\":.275}\n",
    "    }\n",
    "    unit = preprocess(row['Unit']) # standardize unit of measurement syntax\n",
    "    quantity = row['Quantity'] # retrieve the quantity\n",
    "    \n",
    "    # Check if product exists in qties\n",
    "    required = qties[ingredient]\n",
    "    \n",
    "    # Check if the required quantity for the given unit is met\n",
    "    if unit in required:\n",
    "        required_quantity = required[unit] # retrieve the minimum required quantity\n",
    "        return quantity >= required_quantity # check if the quantity is the minimum\n",
    "    return False\n",
    "\n",
    "# Combined function to filter based on acceptable, must have, and unacceptable keywords\n",
    "def keyword_and_qty(df:pd.DataFrame,ingredient:str):\n",
    "    # acceptable keywords for each ingredient\n",
    "    # slight overlap with the must-have keywords\n",
    "    keywords = {\n",
    "        \"unsalted butter\":[\"unsalted\",\"butter\",\"quarter\",\"stick\"],\n",
    "        \"white sugar\":[\"granulated\",\"white\",\"cane\",\"pure\"],\n",
    "        \"all-purpose flour\":[\"purpose\",\"flour\",\"all\"],\n",
    "        \"vanilla extract\":[\"vanilla\",\"extract\",\"pure\"],\n",
    "        \"dark brown sugar\":[\"brown\",\"sugar\",\"pure\"],\n",
    "        \"large eggs\":[\"large\",\"egg\"],\n",
    "        \"baking soda\":[\"baking\",\"soda\"],\n",
    "        \"semisweet chocolate chips\":[\"chocolate\",'chip','semi','sweet'],\n",
    "        \"chopped walnuts\":[\"walnut\",\"chopped\"]\n",
    "    }\n",
    "    # must_have keywords for each ingredient\n",
    "    must_have = {\n",
    "        \"unsalted butter\":[\"unsalted\",\"butter\"],\n",
    "        \"white sugar\":[\"sugar\"],\n",
    "        \"all-purpose flour\":[\"purpose\",\"flour\",\"all\"],\n",
    "        \"vanilla extract\":[\"vanilla\",\"extract\"],\n",
    "        \"dark brown sugar\":[\"brown\",\"sugar\",\"dark\"],\n",
    "        \"large eggs\":[\"large\",\"egg\"],\n",
    "        \"baking soda\":[\"baking\",\"soda\"],\n",
    "        \"semisweet chocolate chips\":[\"chocolate\",'chip','semi','sweet'],\n",
    "        \"chopped walnuts\":[\"walnut\"]\n",
    "    }\n",
    "    # unacceptable keywords\n",
    "    bad_keywords = {\n",
    "        \"unsalted butter\":[\"peanut\",\"nut\",\"almond\"],\n",
    "        \"white sugar\":[\"chicken\",\"turbinado\",\"coconut\",\"gum\",\"brown\",\"drink\",'powdered'],\n",
    "        \"all-purpose flour\":[\"almond\",'coconut'],\n",
    "        \"vanilla extract\":[\"almond\",\"mint\",\"paste\",\"bean\"],\n",
    "        \"dark brown sugar\":[\"turbinado\",\"coconut\",'oatmeal','sauce'],\n",
    "        \"large eggs\":[\"hard\",\"boiled\",\"tuna\",\"chicken\",\"beef\"],\n",
    "        \"baking soda\":[\"toothpaste\",\"litter\"],\n",
    "        \"semisweet chocolate chips\":['white'],\n",
    "        \"chopped walnuts\":[\"almond\",\"pecan\",\"peanut\",\"butter\"]\n",
    "    }\n",
    "    df_keyword = filter_rows_by_keywords(df,keywords[ingredient],bad_keywords[ingredient],must_have[ingredient])\n",
    "    if df_keyword.empty: # return empty dataframe\n",
    "        return df_keyword\n",
    "    df_fil = df_keyword[ # filter for items w/ sufficient quantity\n",
    "        df_keyword.apply(lambda row: check_sufficient_quantity(ingredient,row),axis=1)\n",
    "    ]\n",
    "    return df_fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to filter the dataframe based on ingredient\n",
    "# mainly checks for sufficient quantity\n",
    "def fil_res(df:pd.DataFrame,ingredient):\n",
    "    df_fil = keyword_and_qty(df,ingredient)\n",
    "    return df_fil.sort_values(ascending=True,by=\"Price\").head(1) # get minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to sum prices together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sum the \"Price\" column if all dataframes are populated\n",
    "def sum_prices_if_not_empty(df_dict):\n",
    "    total_price = 0\n",
    "    \n",
    "    # Check if any dataframe is empty\n",
    "    for df in df_dict.values():\n",
    "        if df.empty:\n",
    "            return 0  # Return 0 if any dataframe is empty\n",
    "    \n",
    "    # If no dataframe is empty, sum the \"Price\" column from all dataframes\n",
    "    for df in df_dict.values():\n",
    "        total_price += df['Price'].sum()\n",
    "    \n",
    "    return total_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trader Joe's\n",
    "Getting products from Trader Joe's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function creates a dataframe w/ all the product information\n",
    "# based on a search\n",
    "# arguments: the ingredient name\n",
    "def tj_info(ingredient:str):\n",
    "    url = \"https://www.traderjoes.com/api/graphql\"\n",
    "    i = 1 # counting parameter\n",
    "    # initialize list to store all results\n",
    "    results = []\n",
    "    # run through the pages of the search results and save results to the list\n",
    "    # realized that we needed this after butter didn't have relevant results until the later on\n",
    "    while True:\n",
    "        query = {\"operationName\":\"SearchProducts\",\n",
    "                 \"variables\":{\"storeCode\":\"182\",\"availability\":\"1\",\"published\":\"1\",\"search\":ingredient,\"currentPage\":i,\"pageSize\":15},\n",
    "                 \"query\":\"query SearchProducts($search: String, $pageSize: Int, $currentPage: Int, $storeCode: String = \\\"182\\\", $availability: String = \\\"1\\\", $published: String = \\\"1\\\") {\\n  products(\\n    search: $search\\n    filter: {store_code: {eq: $storeCode}, published: {eq: $published}, availability: {match: $availability}}\\n    pageSize: $pageSize\\n    currentPage: $currentPage\\n  ) {\\n    items {\\n      category_hierarchy {\\n        id\\n        url_key\\n        description\\n        name\\n        position\\n        level\\n        created_at\\n        updated_at\\n        product_count\\n        __typename\\n      }\\n      item_story_marketing\\n      product_label\\n      fun_tags\\n      primary_image\\n      primary_image_meta {\\n        url\\n        metadata\\n        __typename\\n      }\\n      other_images\\n      other_images_meta {\\n        url\\n        metadata\\n        __typename\\n      }\\n      context_image\\n      context_image_meta {\\n        url\\n        metadata\\n        __typename\\n      }\\n      published\\n      sku\\n      url_key\\n      name\\n      item_description\\n      item_title\\n      item_characteristics\\n      item_story_qil\\n      use_and_demo\\n      sales_size\\n      sales_uom_code\\n      sales_uom_description\\n      country_of_origin\\n      availability\\n      new_product\\n      promotion\\n      price_range {\\n        minimum_price {\\n          final_price {\\n            currency\\n            value\\n            __typename\\n          }\\n          __typename\\n        }\\n        __typename\\n      }\\n      retail_price\\n      nutrition {\\n        display_sequence\\n        panel_id\\n        panel_title\\n        serving_size\\n        calories_per_serving\\n        servings_per_container\\n        details {\\n          display_seq\\n          nutritional_item\\n          amount\\n          percent_dv\\n          __typename\\n        }\\n        __typename\\n      }\\n      ingredients {\\n        display_sequence\\n        ingredient\\n        __typename\\n      }\\n      allergens {\\n        display_sequence\\n        ingredient\\n        __typename\\n      }\\n      created_at\\n      first_published_date\\n      last_published_date\\n      updated_at\\n      related_products {\\n        sku\\n        item_title\\n        primary_image\\n        primary_image_meta {\\n          url\\n          metadata\\n          __typename\\n        }\\n        price_range {\\n          minimum_price {\\n            final_price {\\n              currency\\n              value\\n              __typename\\n            }\\n            __typename\\n          }\\n          __typename\\n        }\\n        retail_price\\n        sales_size\\n        sales_uom_description\\n        category_hierarchy {\\n          id\\n          name\\n          __typename\\n        }\\n        __typename\\n      }\\n      __typename\\n    }\\n    total_count\\n    page_info {\\n      current_page\\n      page_size\\n      total_pages\\n      __typename\\n    }\\n    __typename\\n  }\\n}\\n\"}\n",
    "        time.sleep(.5) # try not to get banned\n",
    "        # retrieve website information\n",
    "        response = requests.post(url,json=query)\n",
    "        # check for error\n",
    "        response.raise_for_status()\n",
    "        res = response.json() # convert to json\n",
    "        # if no products are returned\n",
    "        # escape the loops\n",
    "        if not res[\"data\"][\"products\"][\"items\"]:\n",
    "            break\n",
    "        results.append(res)\n",
    "        i += 1 # increment counting parameter\n",
    "        print(i) # diagnostic statement\n",
    "    # create list to store product information\n",
    "    prod = [[\n",
    "        subitem[\"item_title\"],\n",
    "        float(subitem[\"retail_price\"]),\n",
    "        subitem[\"sales_size\"],\n",
    "        subitem[\"sales_uom_description\"]\n",
    "        ] for item in results for subitem in item[\"data\"][\"products\"][\"items\"]]\n",
    "    # organize results into dataframe\n",
    "    df = pd.DataFrame(data=prod,columns=[\n",
    "        \"Name\",\"Price\",\"Quantity\",\"Unit\"\n",
    "    ])\n",
    "    df_fil = fil_res(df,ingredient)\n",
    "    return df_fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get search results from Trader Joe's\n",
    "for ingredient in tjs.keys():\n",
    "    print(ingredient) # diagnostic statment\n",
    "    ing_df = tj_info(ingredient) # get the search results from Trader Joe's\n",
    "    tjs[ingredient] = ing_df # update dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results\n",
    "for ingredient in tjs:\n",
    "    print(tjs[ingredient])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_prices_if_not_empty(tjs) # calculate total price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SaveMart\n",
    "Getting products from SaveMart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to retrieve the quantity and unit from each product name\n",
    "def extract_quantity_and_unit(product_name):\n",
    "    # This regex handles potential spacing issues and units at the end of the string\n",
    "    regex = r\"(\\d+(\\.\\d+)?)\\s*(fl\\.?\\s?oz\\.?|oz\\.?|ea|lbs?\\.*|g|ml|kg|sticks|box|pound|gr|cups|tbsp|bottle|jar|ct|pk|count)(?=\\s|$)\"\n",
    "    \n",
    "    # Search for the pattern in the product name\n",
    "    match = re.search(regex, product_name.lower())\n",
    "    # if the pattern exists, get the quantity and unit\n",
    "    if match:\n",
    "        quantity = match.group(1) # the actual number\n",
    "        unit = match.group(3) # unit of measurement\n",
    "        return quantity, unit\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# get product information from each search\n",
    "# and organize into dataframe\n",
    "# query: copied from the developer tools tab\n",
    "def svmrt_info(ingredient:str):\n",
    "    query = {\"query\":\"\\n    query MerchandisedCategory($adCapabilityPackId: AdCapabilityPackId!, $networkId: String!, $siteId: String!, $limit: Int!, $offset: Int!, $taxonomyNodeId: String!, $adsScreenName: String!, $cookie: String, $sortBy: ProductSortDimension, $productQueryMatch: ProductMatchInput!, $storeId: String) {\\n  heroTopAd: singleAd(\\n    adCapabilityPackId: $adCapabilityPackId\\n    adParams: [{key: \\\"position\\\", value: \\\"HeroTop\\\"}, {key: \\\"asn\\\", value: $adsScreenName}, {key: \\\"ca\\\", value: $taxonomyNodeId}, {key: \\\"sz\\\", value: \\\"375x*\\\"}]\\n    networkId: $networkId\\n    siteId: $siteId\\n    placementId: \\\"HeroTop\\\"\\n  ) {\\n    ...ad_ref_list\\n  }\\n  heroBottomAd: singleAd(\\n    adCapabilityPackId: $adCapabilityPackId\\n    adParams: [{key: \\\"position\\\", value: \\\"HeroBottom\\\"}, {key: \\\"asn\\\", value: $adsScreenName}, {key: \\\"ca\\\", value: $taxonomyNodeId}, {key: \\\"sz\\\", value: \\\"375x*\\\"}]\\n    networkId: $networkId\\n    siteId: $siteId\\n    placementId: \\\"HeroBottom\\\"\\n  ) {\\n    ...ad_ref_list\\n  }\\n  browseSubcategories(id: $taxonomyNodeId) @skip(if: true)\\n  navOptionsCategories(id: $taxonomyNodeId)\\n  taxonomy(id: \\\"Mobile/P+C\\\") @skip(if: true) {\\n    __typename\\n    ...taxonomy\\n  }\\n  merchandisedDisplayableObjects(\\n    id: $taxonomyNodeId\\n    taxonomyId: \\\"Mobile/P+C\\\"\\n    positions: [$adsScreenName]\\n  ) @skip(if: true) {\\n    __typename\\n    ... on DisplayableAd {\\n      ...displayable_ad\\n    }\\n    ... on CategoryPreview {\\n      __typename\\n      ads {\\n        ...ad_with_placement\\n      }\\n      categoryId\\n      ... on ProductCategoryPreview {\\n        items {\\n          ...product_summary\\n        }\\n        prefixItems {\\n          ...product_summary_with_ad_telemetry\\n        }\\n      }\\n    }\\n  }\\n  products(\\n    limit: $limit\\n    cookie: $cookie\\n    offset: $offset\\n    taxonomyId: \\\"Mobile/P+C\\\"\\n    sortBy: $sortBy\\n    match: $productQueryMatch\\n    storeId: $storeId\\n  ) {\\n    ...product_result\\n  }\\n}\\n    \\n    fragment ad_ref_list on AdRefList {\\n  __typename\\n  adRef\\n  adList {\\n    ...ad_with_placement\\n  }\\n}\\n    \\n\\n    fragment ad_with_placement on AdWithPlacement {\\n  __typename\\n  position\\n  ad {\\n    __typename\\n    ...ad_with_telemetry\\n  }\\n  placementId\\n}\\n    \\n\\n    fragment ad_with_telemetry on AdDTO {\\n  __typename\\n  adTelemetry {\\n    ...ad_telemetry\\n  }\\n  aid\\n  aiid\\n  height\\n  pid\\n  width\\n  version\\n  ... on CollectionAdDTO {\\n    placements {\\n      ...collection_ad_placement\\n    }\\n    ... on CarouselCollectionDTO {\\n      randomizationStyle\\n    }\\n    title\\n    subtitle\\n  }\\n  ... on ImageAdDTO {\\n    image {\\n      ...ad_image_asset\\n    }\\n  }\\n  ... on ImageCarouselAdDTO {\\n    carouselPages {\\n      ...carousel_page\\n    }\\n  }\\n  ... on LayoutAdDTO {\\n    rows {\\n      __typename\\n      height\\n      columns {\\n        __typename\\n        width\\n        adRef\\n      }\\n    }\\n  }\\n  ... on RoundedImageAdDTO {\\n    image {\\n      ...ad_image_asset\\n    }\\n  }\\n  ... on RoundedImageCarouselAdDTO {\\n    carouselPages {\\n      ...carousel_page\\n    }\\n  }\\n}\\n    \\n\\n    fragment ad_telemetry on AdTelemetry {\\n  __typename\\n  aid\\n  aiid\\n  dimensions {\\n    __typename\\n    key\\n    value\\n  }\\n}\\n    \\n\\n    fragment collection_ad_placement on PlacementDTO {\\n  __typename\\n  height\\n  id\\n  width\\n  ... on LeafPlacementDTO {\\n    adRef\\n    ... on CarouselPlacementDTO {\\n      displayDurationMs\\n    }\\n  }\\n  ... on LayoutRowPlacementDTO {\\n    placements {\\n      ... on LeafPlacementDTO {\\n        adRef\\n        ... on CarouselPlacementDTO {\\n          displayDurationMs\\n        }\\n      }\\n    }\\n  }\\n}\\n    \\n\\n    fragment ad_image_asset on ImageAsset {\\n  __typename\\n  id\\n  densities {\\n    __typename\\n    swiftlyDensity\\n    swiftlyDeviceClass\\n    url\\n  }\\n  altText\\n  revision\\n  action {\\n    __typename\\n    action\\n    name\\n    target\\n  }\\n}\\n    \\n\\n    fragment carousel_page on CarouselPage {\\n  __typename\\n  durationMs\\n  imageAsset {\\n    __typename\\n    ...ad_image_asset\\n  }\\n}\\n    \\n\\n    fragment taxonomy on Taxonomy {\\n  allowedTypes\\n  displayName\\n  id\\n  graph {\\n    children\\n    displayName\\n    id\\n    parents\\n    renderingTemplate\\n    type\\n    images {\\n      ...image_ref\\n    }\\n  }\\n}\\n    \\n\\n    fragment image_ref on ImageRef {\\n  __typename\\n  altText\\n  caption\\n  image(desiredDensity: ThreeX) {\\n    ...image_file\\n  }\\n  images(desiredDensities: [ThreeX]) {\\n    ...image_file\\n  }\\n  type {\\n    ...image_type\\n  }\\n}\\n    \\n\\n    fragment image_file on ImageFile {\\n  __typename\\n  density\\n  device\\n  uri\\n}\\n    \\n\\n    fragment image_type on ImageType {\\n  __typename\\n  description\\n  height\\n  type\\n  width\\n}\\n    \\n\\n    fragment displayable_ad on DisplayableAd {\\n  ad {\\n    ...ad_ref_list\\n  }\\n}\\n    \\n\\n    fragment product_summary on ProductSummary {\\n  __typename\\n  brand\\n  categories\\n  eligibilities {\\n    __typename\\n    eligibilityId\\n  }\\n  legacyPriceTag: fdPriceTag {\\n    ...legacy_price_tag\\n  }\\n  id\\n  images {\\n    ...image_ref\\n  }\\n  ordinal\\n  webPrice {\\n    failure {\\n      type\\n      message\\n      displayMessage\\n    }\\n    success {\\n      basePrice\\n      promoPrice\\n      promoText\\n      isSale\\n    }\\n  }\\n  price {\\n    ...price_result\\n  }\\n  shortDescription\\n  tags {\\n    ...product_tag\\n  }\\n  title\\n  type\\n}\\n    \\n\\n    fragment legacy_price_tag on FamilyDollarPriceTag {\\n  __typename\\n  discountType\\n  finalPrice {\\n    ...legacy_price_detail\\n  }\\n  finalSavings {\\n    ...legacy_savings_detail\\n  }\\n  priceUri\\n  regularPrice {\\n    ...legacy_price_detail\\n  }\\n  scenario\\n  tags {\\n    ...product_tag\\n  }\\n  termsAndConditions\\n}\\n    \\n\\n    fragment legacy_price_detail on PriceDetail {\\n  __typename\\n  buyQuantity\\n  displayPrice\\n  effectiveDate\\n  expirationDate\\n  getQuantity\\n  mixAndMatchId\\n  model\\n  price\\n  quantityLimit\\n  quantityMinimum\\n  soldBy\\n  type\\n}\\n    \\n\\n    fragment legacy_savings_detail on SavingsDetail {\\n  __typename\\n  mustBuyAtLeast\\n  savingsAmount\\n  savingsDisplayAmount\\n  savingsDisplayPercent\\n  savingsPercent\\n  savingsQuantity\\n}\\n    \\n\\n    fragment product_tag on Tag {\\n  __typename\\n  code\\n  description\\n  id\\n  images {\\n    ...image_ref\\n  }\\n  title\\n  type\\n  value\\n}\\n    \\n\\n    fragment price_result on PriceResult {\\n  __typename\\n  failure {\\n    __typename\\n    message\\n    type\\n  }\\n  success {\\n    ...price\\n  }\\n}\\n    \\n\\n    fragment price on Price {\\n  __typename\\n  base {\\n    ...price_model_properties\\n  }\\n  cost {\\n    ...cost\\n  }\\n  info {\\n    ...price_info\\n  }\\n  mixAndMatchId\\n  promotion {\\n    ...price_model_properties\\n  }\\n  savings {\\n    ...savings\\n  }\\n  scenario\\n  soldBy\\n  unit\\n}\\n    \\n\\n    fragment price_model_properties on PriceModelProperties {\\n  __typename\\n  activeThrough {\\n    ...active_through\\n  }\\n  amountOff {\\n    ...money\\n  }\\n  buyQuantity\\n  getQuantity\\n  model\\n  percentOff\\n  price {\\n    ...money\\n  }\\n  type\\n}\\n    \\n\\n    fragment active_through on ActiveThrough {\\n  __typename\\n  end {\\n    ...active_date\\n  }\\n  start {\\n    ...active_date\\n  }\\n}\\n    \\n\\n    fragment active_date on ActiveDate {\\n  __typename\\n  date\\n  time\\n}\\n    \\n\\n    fragment money on Money {\\n  __typename\\n  currency\\n  denomination\\n  value\\n}\\n    \\n\\n    fragment cost on Cost {\\n  __typename\\n  purchaseQuantity\\n  totalCost {\\n    ...money\\n  }\\n  type\\n}\\n    \\n\\n    fragment price_info on PriceInfo {\\n  __typename\\n  code\\n  id\\n  type\\n  value\\n}\\n    \\n\\n    fragment savings on Savings {\\n  __typename\\n  percentSaved\\n  savingsQuantity\\n  totalSavingsAmount {\\n    ...money\\n  }\\n  type\\n}\\n    \\n\\n    fragment product_summary_with_ad_telemetry on ProductSummaryWithAdTelemetry {\\n  __typename\\n  adTelemetry {\\n    ...ad_telemetry\\n  }\\n  product {\\n    ...product_summary\\n  }\\n}\\n    \\n\\n    fragment product_result on ProductResult {\\n  __typename\\n  cookie\\n  count\\n  fieldFacets {\\n    ...field_facet\\n  }\\n  overlapCount\\n  prefixCount\\n  prefixProducts {\\n    ...product_summary_with_ad_telemetry\\n  }\\n  products {\\n    ...product_summary\\n  }\\n  spelling {\\n    __typename\\n    corrected\\n    original\\n  }\\n}\\n    \\n\\n    fragment field_facet on FieldFacet {\\n  __typename\\n  displayName\\n  entries {\\n    ...field_facet_entry\\n  }\\n  field\\n}\\n    \\n\\n    fragment field_facet_entry on FieldFacetEntry {\\n  __typename\\n  count\\n  entry\\n}\\n    \",\n",
    "             \"variables\":{\"adCapabilityPackId\":\"AD_CARACAL_1\",\"adsScreenName\":\"ProductSearch\",\"limit\":50,\"offset\":0,\"taxonomyNodeId\":\"Mobile/P+C/Product/RootCategoryId\",\"networkId\":\"TSMC0.0000000002\",\"siteId\":\"sm-shopperWeb\",\"cookie\":\"\",\"sortBy\":\"Featured\",\"storeId\":\"604\",\"productQueryMatch\":{\"search\":{\"keyword\":ingredient}}}}\n",
    "    url = \"https://savemart.com/graphql\"\n",
    "    # get information from savemart\n",
    "    response = requests.post(url,json=query)\n",
    "    response.raise_for_status() # check for error\n",
    "    response = response.json() # convert to json\n",
    "    # initialize list to store product details\n",
    "    prod = []\n",
    "    # run through each product and add to prod list\n",
    "    for item in response[\"data\"][\"products\"][\"products\"]:\n",
    "        # Check if \"webPrice\" exists and is not None\n",
    "        if item.get(\"webPrice\") and item[\"webPrice\"].get(\"success\"):\n",
    "            # Access the basePrice only if it's safe to do so\n",
    "            # base price is the price without any sales\n",
    "            # from the base price key\n",
    "            price = item[\"webPrice\"][\"success\"].get(\"basePrice\")\n",
    "            # retrieve the price\n",
    "            try: # most prices are in $ format\n",
    "                actual_price = re.findall(r'\\$(.*?)</span>', price)[0]\n",
    "            except: # handle the price w/ 99¢\n",
    "                actual_price = re.findall(r'>(.*?)</span>', price)[0]\n",
    "                # strip the 99¢\n",
    "                actual_price = \"0.\"+actual_price.strip(\"¢\")\n",
    "            # retrieve quantity and unit\n",
    "            try: \n",
    "                qty,unit = extract_quantity_and_unit(item[\"title\"])\n",
    "            except: # return none if fails\n",
    "                qty = None\n",
    "                unit = None\n",
    "            # update list\n",
    "            prod.append([item[\"brand\"],actual_price,item[\"title\"],qty,unit])\n",
    "        else: # if no webprice or success, nothing is returned\n",
    "            print(\"Price details not available\")\n",
    "    # create dataframe w/ results\n",
    "    svmrt = pd.DataFrame(data=prod,columns=[\n",
    "        \"Brand\",\"Price\",\"Name\",\"Quantity\",\"Unit\"\n",
    "    ])\n",
    "    # convert columns to numeric\n",
    "    svmrt[\"Price\"] = pd.to_numeric(svmrt['Price'], errors='coerce')\n",
    "    svmrt[\"Quantity\"] = pd.to_numeric(svmrt['Quantity'], errors='coerce')\n",
    "    svmrt_fil = fil_res(svmrt,ingredient)\n",
    "    return svmrt_fil # return the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run through list of ingredients\n",
    "# and get results from savemart\n",
    "for ingredient in svmrt.keys():\n",
    "    time.sleep(.2) # try not to get banned\n",
    "    ing_df = svmrt_info(ingredient) # get information from SaveMart\n",
    "    svmrt[ingredient] = ing_df # update dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check results\n",
    "for ingredient in svmrt:\n",
    "    print(svmrt[ingredient])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_prices_if_not_empty(svmrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Safeway\n",
    "Get products from Safeway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the search results form safeway\n",
    "def safeway_search(ingredient:str):\n",
    "    # initialize cookies\n",
    "    s = requests.Session()\n",
    "    s.cookies\n",
    "    url = 'https://www.safeway.com/abs/pub/xapi/search/products'\n",
    "    i = 0 # start value\n",
    "    rows = 30 # results per query\n",
    "    all_res = [] # list to store all results\n",
    "    # loop through the search page results\n",
    "    # and exit when no results are returned\n",
    "    while True:  \n",
    "        # search parameters\n",
    "        params = {\n",
    "            'q': ingredient,\n",
    "            'rows': rows,\n",
    "            'start': i, \n",
    "            'search-type': 'keyword',\n",
    "            'request-id': '3998633988543',\n",
    "            'storeid': 3132, \n",
    "            'pagename': 'search',\n",
    "            'url': 'www.safeway.com', \n",
    "            'pageurl': 'www.safeway.com', \n",
    "            'dvid': 'web-autosuggest', \n",
    "            'facet': 'false',\n",
    "            'visitorId': \"\"\n",
    "        }\n",
    "        headers = {'ocp-apim-subscription-key': 'e914eec9448c4d5eb672debf5011cf8f'}\n",
    "        # get the information from safeway\n",
    "        r = requests.get(url, params, headers = headers)\n",
    "        # if no results were returned\n",
    "        # escape the loop\n",
    "        if not r.json()[\"response\"][\"docs\"]:\n",
    "            break\n",
    "        # update list w/ all results\n",
    "        all_res.append(r.json()[\"response\"][\"docs\"])\n",
    "        i += rows # move to next page\n",
    "        print(i) # diagnostic statement\n",
    "    return all_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the quantity and unit of measurement for each item\n",
    "# which is after the dash\n",
    "def extract_after_dash_regex(input_string):\n",
    "    # Regular expression to find everything after \" - \"\n",
    "    match = re.search(r'[–-]\\s*(.+)', input_string)\n",
    "    if match: # if the dash expression exists, return part after the dash\n",
    "        return match.group(1)  # Return the part after \" - \"\n",
    "    return \"\"  # Return an empty string if no match is found\n",
    "\n",
    "# extract the quantity and unit of measurement from the string\n",
    "def extract_quantity_and_unit(input_string):\n",
    "    # Regular expression to match a quantity (number) followed by a unit of measurement (letters)\n",
    "    pattern = r'(\\d+(\\.\\d+)?)\\s*([A-Za-z\\.]+(?:\\s[A-Za-z\\.]+)?)'\n",
    "    match = re.search(pattern, input_string) # find the qty and unit of measurement\n",
    "    if match: # if the qty and unit of measurement exist, extract them\n",
    "        quantity = float(match.group(1))  # Extract the quantity (number)\n",
    "        unit = match.group(3)  # Extract the unit of measurement\n",
    "        return quantity, unit\n",
    "    return None, None  # Return None if no match is found\n",
    "\n",
    "# get the search results from safeway\n",
    "# and organize into a pandas dataframe\n",
    "def get_saf_prod(ingredient:str):\n",
    "    # get search results\n",
    "    search_res = safeway_search(ingredient)\n",
    "    # initialize list to store most important results\n",
    "    search_list = []\n",
    "    # run through search results and populate list\n",
    "    for item in search_res:\n",
    "        for subitem in item:\n",
    "            name = subitem[\"name\"] # product name\n",
    "            price = subitem[\"basePrice\"] # non-sale price\n",
    "            # extract the qty and units of measurement\n",
    "            qty_meas = extract_after_dash_regex(name)\n",
    "            qty,unit = extract_quantity_and_unit(qty_meas)\n",
    "            # organize results into list\n",
    "            subitem_lst = [name,price,qty,unit]\n",
    "            # update master list\n",
    "            search_list.append(subitem_lst)\n",
    "    # organize results into dataframe\n",
    "    df = pd.DataFrame(data=search_list,columns=[\"Name\",\"Price\",\"Quantity\",\"Unit\"])\n",
    "    df = fil_res(df,ingredient)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run through the ingredients\n",
    "# and search for them on safeway\n",
    "for ingredient in sfwy.keys():\n",
    "    time.sleep(.2) # try not to get banned\n",
    "    ing_df = get_saf_prod(ingredient) # get ingredients from safeway\n",
    "    sfwy[ingredient] = ing_df # update dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check results\n",
    "for ingredient in sfwy.keys():\n",
    "    print(sfwy[ingredient])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate total price\n",
    "sum_prices_if_not_empty(sfwy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from urllib.parse import quote, unquote\n",
    "from html import unescape\n",
    "import json\n",
    "\n",
    "# Endpoint and headers\n",
    "url = \"https://redsky.target.com/redsky_aggregations/v1/web/plp_search_v2?\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36'}\n",
    "\n",
    "# List of ingredients to be able to loop\n",
    "ingredients = [\"unsalted butter\", \"granulated sugar\", \"brown sugar\", \"eggs\", \"vanilla extract\", \"baking soda\", \"all purpose flour\", \"semi-sweet chocolate chip\", \"chopped walnuts\"]\n",
    "\n",
    "# Parameters for the API\n",
    "parameters = {\n",
    "    \"key\": \"9f36aeafbe60771e321a7cc95a78140772ab3e96\",\n",
    "    \"channel\": \"WEB\",\n",
    "    \"count\": 24,\n",
    "    \"default_purchasability_filter\": \"true\",\n",
    "    \"include_dmc_dmr\": \"true\",\n",
    "    \"include_sponsored\": \"true\",\n",
    "    \"new_search\": \"true\",\n",
    "    \"platform\": \"desktop\",\n",
    "    \"pricing_store_id\": 2455,\n",
    "    \"spellcheck\": \"true\",\n",
    "    \"store_ids\": [2455, 2268, 2408, 310, 3384],\n",
    "    \"visitor_id\": \"01939852639E02019551A1FC131A3326\",\n",
    "    \"zip\": 95616\n",
    "}\n",
    "\n",
    "def target_scraper(ingredient, regex_pattern):\n",
    "    all_results = []\n",
    "    offset = 0\n",
    "\n",
    "    while True:\n",
    "        # Update parameters dynamically for each request\n",
    "        encoded_ingredient = quote(ingredient)\n",
    "        parameters[\"keyword\"] = ingredient\n",
    "        parameters[\"page\"] = f\"/s/{encoded_ingredient}\"\n",
    "        parameters[\"offset\"] = offset\n",
    "\n",
    "        response = requests.get(url, params=parameters, headers=headers)\n",
    "        \n",
    "        # Check if response is successful\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error fetching data for {ingredient}: {response.status_code}\")\n",
    "            break\n",
    "\n",
    "        # Load response data\n",
    "        try:\n",
    "            data = response.json()\n",
    "            products = data[\"data\"][\"search\"][\"products\"]\n",
    "        except (KeyError, json.JSONDecodeError):\n",
    "            print(f\"Error parsing data for {ingredient}\")\n",
    "            break\n",
    "        \n",
    "        # If no more products, exit loop\n",
    "        if not products:\n",
    "            break\n",
    "\n",
    "        # Extract product name and price\n",
    "        for product in products:\n",
    "            title = product['item']['product_description']['title']\n",
    "            price = product['price']['current_retail']\n",
    "            decoded_title = unescape(unquote(title))\n",
    "\n",
    "            # Filter products based on the regex pattern\n",
    "            if re.search(regex_pattern, decoded_title, flags=re.IGNORECASE):\n",
    "                all_results.append({'ingredient': ingredient, 'product_name': decoded_title, 'price': price})\n",
    "\n",
    "        # Increment offset for next page\n",
    "        offset += 24\n",
    "\n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "# Define ingredient list and their filtering terms\n",
    "filter_terms = {\n",
    "    \"unsalted butter\": r\"unsalted butter\",\n",
    "    \"granulated sugar\": r\"granulated sugar\",\n",
    "    \"brown sugar\": r\" dark brown sugar\",\n",
    "    \"eggs\": r\"eggs\",\n",
    "    \"vanilla extract\": r\"vanilla extract\",\n",
    "    \"baking soda\": r\"baking soda\",\n",
    "    \"all purpose flour\": r\"all purpose flour|all\\-purpose flour\",\n",
    "    \"semi-sweet chocolate chip\": r\"semi sweet chocolate|semi\\-sweet chocolate\",\n",
    "    \"chopped walnuts\": r\"chopped walnuts\"\n",
    "}\n",
    "\n",
    "# Loop through each ingredient and collect data\n",
    "main_df = pd.DataFrame()\n",
    "for ingredient, regex_pattern in filter_terms.items():\n",
    "    print(f\"Scraping for: {ingredient}\")\n",
    "    ingredient_df = target_scraper(ingredient, regex_pattern)\n",
    "    main_df = pd.concat([main_df, ingredient_df], ignore_index=True)\n",
    "\n",
    "main_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "def extract_amount(product_name):\n",
    "    # Extracing the amount by using common units\n",
    "    matches = re.findall(r\"(\\d+\\.?\\d*)\\s?(fl\\.?\\s?oz|oz|lb|lbs|g|kg|ml|l|ct|pcs|pack|case|floz)\", product_name, re.IGNORECASE)\n",
    "    if matches:\n",
    "        return f\"{matches[-1][0]} {matches[-1][1].replace('.', '').lower()}\"\n",
    "    return None\n",
    "\n",
    "# Creates an amount value for each of the products\n",
    "main_df[\"amount\"] = main_df[\"product_name\"].apply(extract_amount)\n",
    "\n",
    "# Remove rows with None in the \"amount\" column\n",
    "main_df = main_df[main_df[\"amount\"].notna()]\n",
    "\n",
    "def filter_eggs(df):\n",
    "    # Filtering out egg products that contain the word large, candy, or hard since they are not the type of eggs we are looking for\n",
    "    return df[~((df[\"ingredient\"] == \"eggs\") & \n",
    "                ((df[\"product_name\"].str.contains(\"hard\", case=False)) | \n",
    "                 (~df[\"product_name\"].str.contains(\"large\", case=False)) |\n",
    "                 (df[\"product_name\"].str.contains(\"candy\", case=False))))]\n",
    "\n",
    "filtered_df = filter_eggs(main_df)\n",
    "\n",
    "# Filter for filtering out products that don't meet our minimum required amount per ingredient\n",
    "FILTER_CRITERIA = {\n",
    "    \"unsalted butter\": {\"lb\": 0.5, \"ct\": 2},\n",
    "    \"granulated sugar\": {\"lb\": 0.5},\n",
    "    \"brown sugar\": {\"lb\": 0.5, \"oz\": 7},\n",
    "    \"eggs\": {\"ct\": 2},\n",
    "    \"all purpose flour\": {\"lb\": 1, \"g\": 120, \"oz\": 4},\n",
    "    \"semi-sweet chocolate chip\": {\"oz\": 12},\n",
    "    \"chopped walnuts\": {\"oz\": 6},\n",
    "    # Baking soda and vanilla extract will not need filtering as all products have enough (1-2 tablespoons)\n",
    "}\n",
    "\n",
    "def meets_criteria(row):\n",
    "    # Filtering out products that dont meet the filtering criteria\n",
    "    ingredient = row[\"ingredient\"]\n",
    "    \n",
    "    # If the ingredient is baking soda or vanilla extract, keep it as is as these products have enough\n",
    "    if ingredient in [\"baking soda\", \"vanilla extract\"]:\n",
    "        return True\n",
    "\n",
    "    amount_unit = row[\"amount\"].split()\n",
    "    \n",
    "    if len(amount_unit) != 2:\n",
    "        return False\n",
    "    \n",
    "    amount, unit = amount_unit\n",
    "    amount = float(amount)\n",
    "    \n",
    "    # Check if the unit and amount match the criteria for this ingredient\n",
    "    if ingredient in FILTER_CRITERIA and unit in FILTER_CRITERIA[ingredient]:\n",
    "        return amount >= FILTER_CRITERIA[ingredient][unit]\n",
    "    \n",
    "    return False\n",
    "\n",
    "filtered_df = filtered_df[filtered_df.apply(meets_criteria, axis=1)]\n",
    "\n",
    "filtered_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "filtered_df = filtered_df.copy()\n",
    "\n",
    "# Sort the DataFrame to prioritize dark brown sugar and lowest price for each ingredient\n",
    "filtered_df.sort_values(by=['ingredient', 'price'], ascending=[True, True], inplace=True)\n",
    "\n",
    "# Drop duplicates to keep only the cheapest product per unique ingredient\n",
    "cheapest_ingredients = filtered_df.drop_duplicates(subset='ingredient', keep='first')\n",
    "\n",
    "cheapest_ingredients.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(cheapest_ingredients[[\"ingredient\",\"product_name\",\"price\",\"amount\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Davis Co-op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endpoint URL and header\n",
    "url = \"https://daviscoop.storebyweb.com/s/1000-1/api/b/\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.3\"}\n",
    "\n",
    "ingredients = [\"unsalted butter\", \"granulated sugar\", \"dark brown sugar\", \"eggs\", \"vanilla extract\", \"baking soda\", \"all purpose flour\", \"semi-sweet chocolate chip\", \"walnuts\"]\n",
    "\n",
    "parameters = {\"facets\": {}, \"ps\": 32, \"s\": \"\", \"g\": []}\n",
    "\n",
    "def coop_scraper(ingredient, regex_pattern):\n",
    "    all_results = []\n",
    "    pn = 1\n",
    "\n",
    "    while True:\n",
    "        parameters[\"pn\"] = pn\n",
    "        parameters[\"q\"] = ingredient\n",
    "\n",
    "        response = requests.post(url, json=parameters, headers=headers)\n",
    "        \n",
    "        # Check if response is successful\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error fetching data for {ingredient}: {response.status_code}\")\n",
    "            break\n",
    "\n",
    "        # Load response data\n",
    "        try:\n",
    "            data = response.json()\n",
    "            products = data.get(\"items\",[])\n",
    "        except (KeyError, json.JSONDecodeError):\n",
    "            print(f\"Error parsing data for {ingredient}\")\n",
    "            break\n",
    "        \n",
    "        # If no more products, exit loop\n",
    "        if not products:\n",
    "            break\n",
    "\n",
    "        # Extract product name and price\n",
    "        for product in products:\n",
    "            title = product['name']\n",
    "            price = product['actualPrice']\n",
    "            amount = product['size']\n",
    "            brand = product['brand']\n",
    "            decoded_title = unescape(unquote(title))\n",
    "\n",
    "            # Filter products based on the regex pattern\n",
    "            if re.search(regex_pattern, decoded_title, flags=re.IGNORECASE):\n",
    "                all_results.append({'ingredient': ingredient, 'product_name': decoded_title, 'price': price, 'amount': amount, \"brand\": brand})\n",
    "\n",
    "        if len(products) < parameters[\"ps\"]:\n",
    "            break\n",
    "\n",
    "        # Increment offset for next page\n",
    "        pn += 1\n",
    "    \n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "# Define ingredient list and their filtering terms\n",
    "filter_terms = {\n",
    "    \"unsalted butter\": r\"unsalted butter\",\n",
    "    \"granulated sugar\": r\"granulated sugar\",\n",
    "    \"brown sugar\": r\"dark brown sugar\",\n",
    "    \"eggs\": r\"eggs\",\n",
    "    \"vanilla extract\": r\"vanilla extract\",\n",
    "    \"baking soda\": r\"baking soda\",\n",
    "    \"all purpose flour\": r\"all purpose flour|all\\-purpose flour\",\n",
    "    \"semi-sweet chocolate chip\": r\"semi sweet chocolate|semi\\-sweet chocolate\",\n",
    "    \"walnuts\": r\"walnuts\"\n",
    "}\n",
    "\n",
    "main2_df = pd.DataFrame()\n",
    "for ingredient, regex_pattern in filter_terms.items():\n",
    "    print(f\"Scraping for: {ingredient}\")\n",
    "    ingredient_df = coop_scraper(ingredient, regex_pattern)\n",
    "    main2_df = pd.concat([main2_df, ingredient_df], ignore_index=True)\n",
    "\n",
    "main2_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "def filter_eggs(df):\n",
    "    # Exclude products that contain words that signal on egg products we are not looking for\n",
    "    return df[~((df[\"ingredient\"] == \"eggs\") & \n",
    "                ((df[\"product_name\"].str.contains(\"hard\", case=False)) | \n",
    "                 (~df[\"product_name\"].str.contains(\"large\", case=False)) |\n",
    "                 (df[\"product_name\"].str.contains(\"candy\", case=False))))]\n",
    "\n",
    "def filter_brown_sugar(df):\n",
    "    # Exclude products that contain keywords like wafels that we are not looking for\n",
    "    return df[~((df[\"ingredient\"] == \"brown sugar\") & \n",
    "                ((df[\"product_name\"].str.contains(\"creamer\", case=False)) | \n",
    "                 (df[\"product_name\"].str.contains(\"maple\", case=False)) |\n",
    "                 (df[\"product_name\"].str.contains(\"replacement\", case=False)) |\n",
    "                 (df[\"product_name\"].str.contains(\"wafels\", case=False)) |\n",
    "                 (df[\"product_name\"].str.contains(\"ice\", case=False)) |\n",
    "                 (df[\"product_name\"].str.contains(\"milk\", case=False)) |\n",
    "                 (df[\"product_name\"].str.contains(\"latte\", case=False))))]\n",
    "\n",
    "def filter_walnuts(df):\n",
    "    # Excluding walnut products from sprouted as they are not the type of walnuts we are looking for\n",
    "    return df[~((df[\"ingredient\"] == \"walnuts\") & \n",
    "                ((df[\"product_name\"].str.contains(\"sprouted\", case=False))))]\n",
    "\n",
    "filtered_df2 = filter_eggs(main2_df)\n",
    "filtered_df2 = filter_brown_sugar(filtered_df2)\n",
    "filtered_df2 = filter_walnuts(filtered_df2)\n",
    "\n",
    "# Filter for filtering out products that don't meet our minimum required amount per ingredient\n",
    "FILTER_CRITERIA = {\n",
    "    \"unsalted butter\": {\"oz.\": 8},\n",
    "    \"granulated sugar\": {\"oz.\": 8},\n",
    "    \"brown sugar\": {\"lb.\": 0.5, \"oz.\": 7},\n",
    "    \"eggs\": {\"ct.\": 2},\n",
    "    \"all purpose flour\": {\"lb.\": 1, \"g.\": 120, \"oz.\": 4},\n",
    "    \"semi-sweet chocolate chip\": {\"oz.\": 12},\n",
    "    \"walnuts\": {\"oz.\": 6},\n",
    "    # Baking soda and vanilla extract will not need filtering as all products have enough (1-2 tablespoons)\n",
    "}\n",
    "\n",
    "def meets_criteria(row):\n",
    "    # Filtering out products that dont meet the filtering criteria\n",
    "    ingredient = row[\"ingredient\"]\n",
    "    \n",
    "    # If the ingredient is baking soda or vanilla extract, keep it as is as these products have enough\n",
    "    if ingredient in [\"baking soda\", \"vanilla extract\"]:\n",
    "        return True\n",
    "\n",
    "    amount_unit = row[\"amount\"].split()\n",
    "    \n",
    "    if len(amount_unit) != 2:\n",
    "        return False\n",
    "    \n",
    "    amount, unit = amount_unit\n",
    "    amount = float(amount)\n",
    "    \n",
    "    # Check if the unit and amount match the criteria for this ingredient\n",
    "    if ingredient in FILTER_CRITERIA and unit in FILTER_CRITERIA[ingredient]:\n",
    "        return amount >= FILTER_CRITERIA[ingredient][unit]\n",
    "    \n",
    "    return False\n",
    "\n",
    "def preprocess_amount_column(df):\n",
    "    # Some rows have invalid format so clean out the data frame to be able to run the filtering code by making sure every value in \"amount\" is a valid format\n",
    "    cleaned_rows = []\n",
    "    for index, row in df.iterrows():\n",
    "        amount_unit = row[\"amount\"].split()\n",
    "        if len(amount_unit) == 2:  # Only keep rows with exactly two parts: number and unit\n",
    "            try:\n",
    "                float(amount_unit[0])\n",
    "                cleaned_rows.append(row)\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return pd.DataFrame(cleaned_rows)\n",
    "\n",
    "# Clean the 'amount' column\n",
    "filtered_df2 = preprocess_amount_column(filtered_df2)\n",
    "\n",
    "filtered_df2 = filtered_df2[filtered_df2.apply(meets_criteria, axis=1)]\n",
    "\n",
    "filtered_df2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Ensure a clean DataFrame\n",
    "filtered_df2 = filtered_df2.copy()\n",
    "\n",
    "# Sort the DataFrame to prioritize dark brown sugar and lowest price for each ingredient\n",
    "filtered_df2.sort_values(by=['ingredient', 'price'], ascending=[True, True], inplace=True)\n",
    "\n",
    "# Drop duplicates to keep only the cheapest product per unique ingredient\n",
    "cheapest_ingredients = filtered_df2.drop_duplicates(subset='ingredient', keep='first')\n",
    "\n",
    "cheapest_ingredients.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(cheapest_ingredients)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
