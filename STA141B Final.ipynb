{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: user has to input desired search url\n",
    "\n",
    "code function:\n",
    "1. extracts all recipe links from the search page\n",
    "2. scrapes title, stars, and number of ratings from each of the links extracted\n",
    "3. sorts each recipe according to the descending number of ratings, then descending stars\n",
    "4. converts dictionary into data frame for organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import parse_qs, urlparse\n",
    "\n",
    "# function that extracts each recipe link from search page (url)\n",
    "def extractlinks(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    #extract anchor tags w/ links\n",
    "    cards = soup.find_all('a', href = True)\n",
    "    links = [link['href'] for link in cards if '/recipe/' in link['href']]\n",
    "    \n",
    "    return list(set(links))\n",
    "\n",
    "# function that scrapes title, stars, number of ratings    \n",
    "def scrapedetails(rurl, searchq):\n",
    "    response = requests.get(rurl)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    #scrape title\n",
    "    telement = soup.select_one(\"h1.article-heading\")\n",
    "    title = telement.get_text(strip = True) if telement else \"n/a\"\n",
    "    \n",
    "    #scrape stars (0 - 5)\n",
    "    selement = soup.select_one(\"div.mm-recipes-review-bar__rating.mntl-text-block.text-label-300\")\n",
    "    stars = float(selement.get_text(strip = True)) if selement else 0.0\n",
    "    \n",
    "    #scrape number of ratings\n",
    "    relement = soup.select_one(\"div.mm-recipes-review-bar__rating-count.mntl-text-block.text-label-300\")\n",
    "    \n",
    "    #if/else to determine if rating number exists. \n",
    "    if relement:\n",
    "        #note: if exists, it strips html of text (such as </div>) and ()\n",
    "        ratingtext = relement.get_text(strip = True)\n",
    "        ratingnum = int(ratingtext.strip(\"()\").replace(\",\", \"\"))\n",
    "    else:\n",
    "        ratingnum = 0\n",
    "    \n",
    "    #matching search keywords with title\n",
    "    if searchq.lower() not in title.lower():\n",
    "        return None\n",
    "    \n",
    "    #dictionary for details scraped\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"stars\": stars,\n",
    "        \"ratings\": ratingnum\n",
    "    }\n",
    "    \n",
    "# function that fetches recipe from search page, then uses scrapedetails() to scrape specifics\n",
    "def scrapeall(url, searchq):\n",
    "    links = extractlinks(url)\n",
    "    \n",
    "    #list to store recipe links\n",
    "    allrecipes = []\n",
    "    \n",
    "    #loops through each link and calls previous function to scrape details\n",
    "    for link in links:\n",
    "        rdetails = scrapedetails(link, searchq)\n",
    "        if rdetails:\n",
    "            #update list to store dictionary\n",
    "            allrecipes.append(rdetails)\n",
    "    \n",
    "    return allrecipes\n",
    "\n",
    "# sort function that sorts by descending number of ratings first, then descending number of stars\n",
    "def sort(recipes): \n",
    "    rsorted = sorted(recipes, key = lambda x: (-x['ratings'], -x['stars']))\n",
    "    return rsorted\n",
    "\n",
    "# extract serach query from url\n",
    "def extractsearchq(url):\n",
    "    query = parse_qs(urlparse(url).query)\n",
    "    search = query.get(\"q\", [\"\"])[0]\n",
    "    searchq = search.replace(\"+\", \" \")\n",
    "    return searchq\n",
    "\n",
    "# main function\n",
    "def main():\n",
    "    url = input(\"paste search url here:\")\n",
    "    # specifically https://www.allrecipes.com/search?q=chocolate+chip+cookies for our project\n",
    "    searchq = extractsearchq(url)\n",
    "    recipes = scrapeall(url, searchq)\n",
    "    rsorted = sort(recipes)\n",
    "    \n",
    "    #convert to data frame for organization purposes\n",
    "    df = pd.DataFrame(rsorted)\n",
    "    df.insert(0, \"rank\", range(1, 1 + len(df)))\n",
    "    print(df.to_string(index = False))\n",
    "\n",
    "# call main function\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
